{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b237aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd247e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input file \n",
    "df=pd.read_excel(\"UniversityLinks.xlsx\")\n",
    "\n",
    "#Stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#positive-negative\n",
    "#path to positive and negative text files\n",
    "\n",
    "positive_words=pd.read_csv(\"positive-words.txt\",header=None)[0].tolist()\n",
    "negative_words=pd.read_csv(\"negative-words.txt\",header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64311f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "options=Options()\n",
    "options.headless=True\n",
    "options.add_argument('window-size=1920x1080') #your Screen resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc0957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=df['University_Links']\n",
    "\n",
    "URLs=[]\n",
    "positive_score_list=[]\n",
    "negative_score_list=[]\n",
    "polarity_score_list=[]\n",
    "subjective_score_list=[]\n",
    "avg_sent_len_list=[]\n",
    "percent_complex_word_list=[]\n",
    "Fog_index_list=[]\n",
    "avg_num_of_words_per_sent_list=[]\n",
    "complex_word_count_list=[]\n",
    "word_count_list=[]\n",
    "syllable_per_word_list=[]\n",
    "personal_pronoun_list=[]\n",
    "avg_word_length_list=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15a6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positivescore(result,positive_words):\n",
    "    counter=0\n",
    "    for ele in result:\n",
    "        if ele in positive_words:\n",
    "            counter=counter+1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccbdcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negativescore(result,negative_words):\n",
    "    counter=0\n",
    "    for ele in result:\n",
    "        if ele in negative_words:\n",
    "            counter=counter+1\n",
    "    return counter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdf9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagesentlen(result,res_without_puntuations):\n",
    "    sent_tokens = nltk.sent_tokenize(result)\n",
    "    avg_sent_len=len(res_without_puntuations)/len(sent_tokens)\n",
    "    return avg_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d58c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(result,stop_words):\n",
    "    num_of_words=0\n",
    "    for ele in result:\n",
    "        if ele not in stop_words:\n",
    "                num_of_words=num_of_words+1\n",
    "    return num_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64061609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexword(result,stop_words):\n",
    "    words=[]\n",
    "    for ele in result:\n",
    "        if ele not in stop_words:\n",
    "            words.append(ele)\n",
    "    Complex_count=0\n",
    "    for word in words:\n",
    "        SyllablePerWord=0\n",
    "        for w in word:\n",
    "            if (w=='a' or w=='e' or w=='i' or w=='o' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U'):\n",
    "                SyllablePerWord+=1\n",
    "        if word.endswith(\"ed\" or \"es\"):\n",
    "            SyllablePerWord-=1\n",
    "        if SyllablePerWord>=3:\n",
    "            Complex_count+=1\n",
    "    return Complex_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfc3dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Syllable(result,stop_words):\n",
    "    words=[]\n",
    "    for ele in result:\n",
    "        if ele not in stop_words:\n",
    "            words.append(ele)\n",
    "    Syllable_count=0\n",
    "    for word in words:\n",
    "        for w in word:\n",
    "            if (w=='a' or w=='e' or w=='i' or w=='o' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U'):\n",
    "                Syllable_count+=1\n",
    "        if word.endswith(\"ed\" or \"es\"):\n",
    "            Syllable_count-=1\n",
    "    return Syllable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c0340bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronoun(result):\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounRegex.findall(result)\n",
    "    return len(pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cadc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(res_without_puntuations):\n",
    "    letters=0\n",
    "    for word in res_without_puntuations:\n",
    "        for w in word:\n",
    "            letters=letters+1\n",
    "    avg=letters/len(res_without_puntuations)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065a437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    path = Service('chromedriver.exe')  #path to chromedriver\n",
    "    driver = webdriver.Chrome(service=path, options=options)\n",
    "    driver.get(link)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,\"//h1[@class='text-white']\").text\n",
    "        content_list=[]\n",
    "\n",
    "\n",
    "        more_link = driver.find_element(By.XPATH,'//*[@id=\"p2-overview\"]/div[3]/div/div/div[1]/p/span/a')\n",
    "        more_link.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        cont=driver.find_elements(By.XPATH,'//*[@id=\"p2-overview\"]/div[3]/div/div/div[2]/p')\n",
    "        for i in cont:\n",
    "                content_list.append(i.text)\n",
    "\n",
    "\n",
    "        delim = \"\"\n",
    "        textoutput =  delim.join(content_list)\n",
    "\n",
    "        URLs.append(link)\n",
    "\n",
    "        result = title + \" \" + textoutput\n",
    "\n",
    "        title=title.replace('?','')\n",
    "        title=title.replace(':','')\n",
    "        with open(f'Text Output/{title}.txt','w+',encoding='utf-8') as file:    #path to store Text-output files\n",
    "            file.write(str(result))\n",
    "\n",
    "\n",
    "        res_without_puntuations=tokenizer.tokenize(result)\n",
    "        res_without_stopwords=[]\n",
    "        for ele in res_without_puntuations:\n",
    "            if ele not in stop_words:\n",
    "                res_without_stopwords.append(ele)\n",
    "\n",
    "        #positive score\n",
    "        positive_score=positivescore(res_without_stopwords,positive_words)\n",
    "        positive_score_list.append(positive_score)\n",
    "\n",
    "        #negative score\n",
    "        negative_score=negativescore(res_without_stopwords,negative_words)\n",
    "        negative_score_list.append(negative_score)\n",
    "\n",
    "        #polarity score\n",
    "        polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "        polarity_score_list.append(polarity_score)\n",
    "\n",
    "        #subjective score\n",
    "        subjective_score=(positive_score + negative_score)/ (len(res_without_stopwords) + 0.000001)\n",
    "        subjective_score_list.append(subjective_score)\n",
    "\n",
    "        #Average Sentence Length\n",
    "        average_sent_length=averagesentlen(result,res_without_puntuations)\n",
    "        avg_sent_len_list.append(average_sent_length)\n",
    "\n",
    "\n",
    "        #Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
    "        avg_num_of_words_per_sent=average_sent_length\n",
    "        avg_num_of_words_per_sent_list.append(avg_num_of_words_per_sent)\n",
    "\n",
    "        #Complex Word Count\n",
    "        complex_word_count=complexword(res_without_puntuations,stop_words)\n",
    "        complex_word_count_list.append(complex_word_count)\n",
    "\n",
    "        #Word Count\n",
    "        number_of_words = word_count(res_without_puntuations,stop_words)\n",
    "        word_count_list.append(number_of_words)\n",
    "\n",
    "        #Percentage of Complex words  = the number of complex words / the number of words\n",
    "        percent_complex_word=100*complex_word_count/number_of_words\n",
    "        percent_complex_word_list.append(percent_complex_word)\n",
    "\n",
    "        #Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "        Fog_index=0.4*(average_sent_length + percent_complex_word)\n",
    "        Fog_index_list.append(Fog_index)\n",
    "\n",
    "\n",
    "        #Syllable Count Per Word      \n",
    "        Syallable_count=Syllable(res_without_puntuations,stop_words)\n",
    "        Syllable_per_word=Syallable_count/number_of_words\n",
    "        syllable_per_word_list.append(Syllable_per_word)\n",
    "\n",
    "\n",
    "        #Personal Pronouns.\n",
    "        personal_pronoun=pronoun(result)\n",
    "        personal_pronoun_list.append(personal_pronoun)\n",
    "\n",
    "        #Average Word Length\n",
    "        avg_word_length=average_word_length(res_without_puntuations)\n",
    "        avg_word_length_list.append(avg_word_length)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c451dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame({'URL':URLs, 'POSITIVE SCORE':positive_score_list, 'NEGATIVE SCORE':negative_score_list, 'POLARITY SCORE':polarity_score_list, 'SUBJECTIVE SCORE':subjective_score_list, 'AVG SENTENCE LENGTH':avg_sent_len_list, 'PERCENTAGE OF COMPLEX WORDS':percent_complex_word_list, 'FOG INDEX':Fog_index_list, 'AVG NUMBER OF WORDS PER SENTENCE':avg_num_of_words_per_sent_list, 'COMPLEX WORD COUNT':complex_word_count_list, 'WORD COUNT':word_count_list, 'SYLLABLE PER WORD':syllable_per_word_list, 'PERSONAL PRONOUNS':personal_pronoun_list, 'AVG WORD LENGTH':avg_word_length_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d938c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_excel('Output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eded009",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
